package architecture

import (
	"context"
	"fmt"
	"runtime"
	"sync"
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"

	"mutual-friend/pkg/cache"
	"mutual-friend/pkg/config"
	"mutual-friend/pkg/redis"
)

// ArchitectureTester ì•„í‚¤í…ì²˜ í…ŒìŠ¤íŠ¸ êµ¬ì¡°ì²´
type ArchitectureTester struct {
	cacheService cache.Cache
	ctx          context.Context
	metrics      *ArchitectureMetrics
}

// ArchitectureMetrics ì•„í‚¤í…ì²˜ ê´€ë ¨ ë©”íŠ¸ë¦­
type ArchitectureMetrics struct {
	mu                          sync.RWMutex
	
	// ë‹¨ì¼ ì¥ì• ì  ë©”íŠ¸ë¦­
	SinglePointsOfFailure       []string
	CriticalPathDependencies    int
	ServiceAvailability         map[string]float64
	
	// í™•ì¥ì„± ë©”íŠ¸ë¦­
	HorizontalScalability       float64  // 0-100%
	VerticalScalability         float64  // 0-100%
	ScalabilityBottlenecks      []string
	ResourceUtilizationRatio    float64
	
	// ê²°í•©ë„ ë° ì‘ì§‘ë„ ë©”íŠ¸ë¦­
	ComponentCoupling           map[string]int
	InterfaceCohesion           float64
	ModuleDependencies          map[string][]string
	CircularDependencies        []string
	
	// ì„±ëŠ¥ ì•„í‚¤í…ì²˜ ë©”íŠ¸ë¦­
	LayerLatency                map[string]time.Duration
	ComponentThroughput         map[string]float64
	BottleneckIdentification    map[string]string
	
	// ë³µì›ë ¥ ë©”íŠ¸ë¦­
	FaultTolerance              float64  // 0-100%
	GracefulDegradation         float64  // 0-100%
	RecoveryCapability          float64  // 0-100%
	
	// ë°ì´í„° í”Œë¡œìš° ë©”íŠ¸ë¦­
	DataFlowComplexity          int
	DataConsistencyPatterns     []string
	DataBottlenecks             []string
	
	// ë³´ì•ˆ ì•„í‚¤í…ì²˜ ë©”íŠ¸ë¦­
	SecurityLayerDepth          int
	AttackSurfaceArea           int
	SecurityBottlenecks         []string
	
	// ìš´ì˜ ë³µì¡ì„± ë©”íŠ¸ë¦­
	OperationalComplexity       float64  // 0-100%
	MonitoringCoverage          float64  // 0-100%
	DeploymentComplexity        float64  // 0-100%
	
	// ê¸°ìˆ  ë¶€ì±„ ë©”íŠ¸ë¦­
	TechnicalDebtScore          float64  // 0-100%
	LegacyComponentCount        int
	ArchitecturalDrift          float64  // 0-100%
}

// ComponentHealth ì»´í¬ë„ŒíŠ¸ ìƒíƒœ
type ComponentHealth struct {
	Name           string
	Status         string  // "healthy", "degraded", "failed"
	ResponseTime   time.Duration
	ErrorRate      float64
	Availability   float64
	Dependencies   []string
	CriticalPath   bool
}

// ArchitecturalIssue ì•„í‚¤í…ì²˜ ë¬¸ì œ
type ArchitecturalIssue struct {
	Type        string    // "SPOF", "BOTTLENECK", "COUPLING", "SECURITY"
	Severity    string    // "CRITICAL", "HIGH", "MEDIUM", "LOW"
	Component   string
	Description string
	Impact      string
	Solution    string
}

// NewArchitectureTester ì•„í‚¤í…ì²˜ í…ŒìŠ¤í„° ìƒì„±
func NewArchitectureTester(t *testing.T) *ArchitectureTester {
	// ì„¤ì • ë¡œë“œ
	cfg, err := config.LoadConfig("../../configs/config.yaml")
	require.NoError(t, err)
	
	// Redis í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
	redisClient, err := redis.NewClient(&redis.Config{
		Address:      cfg.Redis.Address,
		Password:     cfg.Redis.Password,
		Database:     cfg.Redis.Database,
		PoolSize:     cfg.Redis.PoolSize,
		MinIdleConns: cfg.Redis.MinIdleConns,
		MaxRetries:   cfg.Redis.MaxRetries,
		DialTimeout:  time.Duration(cfg.Redis.DialTimeout) * time.Second,
		ReadTimeout:  time.Duration(cfg.Redis.ReadTimeout) * time.Second,
		WriteTimeout: time.Duration(cfg.Redis.WriteTimeout) * time.Second,
	})
	require.NoError(t, err)
	
	// ìºì‹œ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
	cacheService, err := cache.NewService(redisClient)
	require.NoError(t, err)
	
	return &ArchitectureTester{
		cacheService: cacheService,
		ctx:          context.Background(),
		metrics: &ArchitectureMetrics{
			ServiceAvailability:     make(map[string]float64),
			ComponentCoupling:       make(map[string]int),
			ModuleDependencies:      make(map[string][]string),
			LayerLatency:           make(map[string]time.Duration),
			ComponentThroughput:    make(map[string]float64),
			BottleneckIdentification: make(map[string]string),
		},
	}
}

// TestSinglePointsOfFailure ë‹¨ì¼ ì¥ì• ì  í…ŒìŠ¤íŠ¸
func TestSinglePointsOfFailure(t *testing.T) {
	tester := NewArchitectureTester(t)
	defer tester.cacheService.Close()
	
	t.Run("Critical Component Analysis", func(t *testing.T) {
		tester.testCriticalComponentAnalysis(t)
	})
	
	t.Run("Service Dependency Mapping", func(t *testing.T) {
		tester.testServiceDependencyMapping(t)
	})
	
	t.Run("Cascade Failure Simulation", func(t *testing.T) {
		tester.testCascadeFailureSimulation(t)
	})
	
	t.Run("Redundancy Analysis", func(t *testing.T) {
		tester.testRedundancyAnalysis(t)
	})
}

// testCriticalComponentAnalysis ì¤‘ìš” ì»´í¬ë„ŒíŠ¸ ë¶„ì„
func (at *ArchitectureTester) testCriticalComponentAnalysis(t *testing.T) {
	t.Log("ğŸ” Analyzing Critical Components for SPOF")
	
	// ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì •ì˜
	components := []ComponentHealth{
		{
			Name:         "Redis Cache",
			Dependencies: []string{},
			CriticalPath: true,
		},
		{
			Name:         "gRPC Server",
			Dependencies: []string{"Redis Cache", "Friend Service", "Event Service"},
			CriticalPath: true,
		},
		{
			Name:         "Friend Service",
			Dependencies: []string{"DynamoDB", "Cache Service", "Event Service"},
			CriticalPath: true,
		},
		{
			Name:         "Event Service",
			Dependencies: []string{"RabbitMQ"},
			CriticalPath: false,
		},
		{
			Name:         "Search Service",
			Dependencies: []string{"Elasticsearch", "Event Consumer"},
			CriticalPath: false,
		},
		{
			Name:         "DynamoDB",
			Dependencies: []string{},
			CriticalPath: true,
		},
	}
	
	// ê° ì»´í¬ë„ŒíŠ¸ì˜ ìƒíƒœ ê²€ì‚¬
	for i, component := range components {
		health := at.checkComponentHealth(component.Name)
		components[i] = health
		components[i].Dependencies = component.Dependencies
		components[i].CriticalPath = component.CriticalPath
		
		at.metrics.ServiceAvailability[component.Name] = health.Availability
	}
	
	// SPOF ì‹ë³„
	spofComponents := at.identifySPOF(components)
	at.metrics.SinglePointsOfFailure = spofComponents
	
	// ì¤‘ìš” ê²½ë¡œ ì˜ì¡´ì„± ê³„ì‚°
	criticalPathDeps := 0
	for _, comp := range components {
		if comp.CriticalPath {
			criticalPathDeps += len(comp.Dependencies)
		}
	}
	at.metrics.CriticalPathDependencies = criticalPathDeps
	
	t.Logf("=== Critical Component Analysis Results ===")
	for _, comp := range components {
		status := "âœ…"
		if comp.Status == "degraded" {
			status = "ğŸŸ¡"
		} else if comp.Status == "failed" {
			status = "ğŸ”´"
		}
		
		t.Logf("%s %s: Availability %.2f%%, Response Time %v, Error Rate %.2f%%",
			status, comp.Name, comp.Availability, comp.ResponseTime, comp.ErrorRate)
		
		if comp.CriticalPath {
			t.Logf("   ğŸ¯ Critical Path Component")
		}
		if len(comp.Dependencies) > 0 {
			t.Logf("   ğŸ“¦ Dependencies: %v", comp.Dependencies)
		}
	}
	
	t.Logf("=== SPOF Analysis ===")
	if len(spofComponents) == 0 {
		t.Logf("âœ… No Single Points of Failure detected")
	} else {
		t.Logf("ğŸ”´ Single Points of Failure detected:")
		for _, spof := range spofComponents {
			t.Logf("   - %s", spof)
		}
	}
	
	t.Logf("Critical Path Dependencies: %d", criticalPathDeps)
	
	// SPOF ê²€ì¦
	assert.LessOrEqual(t, len(spofComponents), 2, "Too many single points of failure")
	assert.LessOrEqual(t, criticalPathDeps, 10, "Too many critical path dependencies")
}

// checkComponentHealth ì»´í¬ë„ŒíŠ¸ ìƒíƒœ ê²€ì‚¬
func (at *ArchitectureTester) checkComponentHealth(componentName string) ComponentHealth {
	switch componentName {
	case "Redis Cache":
		return at.checkRedisHealth()
	case "gRPC Server":
		return at.checkGRPCHealth()
	case "Friend Service":
		return at.checkServiceHealth("Friend Service")
	case "Event Service":
		return at.checkServiceHealth("Event Service")
	case "Search Service":
		return at.checkServiceHealth("Search Service")
	case "DynamoDB":
		return at.checkDynamoDBHealth()
	default:
		return ComponentHealth{
			Name:         componentName,
			Status:       "unknown",
			ResponseTime: 0,
			ErrorRate:    0,
			Availability: 0,
		}
	}
}

// checkRedisHealth Redis ìƒíƒœ ê²€ì‚¬
func (at *ArchitectureTester) checkRedisHealth() ComponentHealth {
	start := time.Now()
	
	// Redis ì—°ê²° í…ŒìŠ¤íŠ¸
	testKey := "health_check"
	testValue := "ping"
	
	err := at.cacheService.Set(at.ctx, testKey, testValue, time.Minute)
	responseTime := time.Since(start)
	
	availability := 100.0
	errorRate := 0.0
	status := "healthy"
	
	if err != nil {
		availability = 0.0
		errorRate = 100.0
		status = "failed"
	} else if responseTime > 100*time.Millisecond {
		availability = 80.0
		status = "degraded"
	}
	
	return ComponentHealth{
		Name:         "Redis Cache",
		Status:       status,
		ResponseTime: responseTime,
		ErrorRate:    errorRate,
		Availability: availability,
	}
}

// checkGRPCHealth gRPC ì„œë²„ ìƒíƒœ ê²€ì‚¬
func (at *ArchitectureTester) checkGRPCHealth() ComponentHealth {
	// gRPC ì„œë²„ ìƒíƒœ ì‹œë®¬ë ˆì´ì…˜
	// ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” gRPC í—¬ìŠ¤ì²´í¬ ì‚¬ìš©
	
	responseTime := time.Millisecond * 50 // ì‹œë®¬ë ˆì´ì…˜ëœ ì‘ë‹µ ì‹œê°„
	availability := 99.5
	errorRate := 0.5
	status := "healthy"
	
	return ComponentHealth{
		Name:         "gRPC Server",
		Status:       status,
		ResponseTime: responseTime,
		ErrorRate:    errorRate,
		Availability: availability,
	}
}

// checkServiceHealth ì„œë¹„ìŠ¤ ìƒíƒœ ê²€ì‚¬
func (at *ArchitectureTester) checkServiceHealth(serviceName string) ComponentHealth {
	// ì„œë¹„ìŠ¤ë³„ ìƒíƒœ ì‹œë®¬ë ˆì´ì…˜
	var responseTime time.Duration
	var availability float64
	var errorRate float64
	status := "healthy"
	
	switch serviceName {
	case "Friend Service":
		responseTime = time.Millisecond * 30
		availability = 99.8
		errorRate = 0.2
	case "Event Service":
		responseTime = time.Millisecond * 20
		availability = 99.0
		errorRate = 1.0
	case "Search Service":
		responseTime = time.Millisecond * 100
		availability = 98.5
		errorRate = 1.5
		status = "degraded"
	}
	
	return ComponentHealth{
		Name:         serviceName,
		Status:       status,
		ResponseTime: responseTime,
		ErrorRate:    errorRate,
		Availability: availability,
	}
}

// checkDynamoDBHealth DynamoDB ìƒíƒœ ê²€ì‚¬
func (at *ArchitectureTester) checkDynamoDBHealth() ComponentHealth {
	// DynamoDB ìƒíƒœ ì‹œë®¬ë ˆì´ì…˜
	// ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” DynamoDB ì—°ê²° í…ŒìŠ¤íŠ¸ ìˆ˜í–‰
	
	responseTime := time.Millisecond * 80
	availability := 99.9
	errorRate := 0.1
	status := "healthy"
	
	return ComponentHealth{
		Name:         "DynamoDB",
		Status:       status,
		ResponseTime: responseTime,
		ErrorRate:    errorRate,
		Availability: availability,
	}
}

// identifySPOF SPOF ì‹ë³„
func (at *ArchitectureTester) identifySPOF(components []ComponentHealth) []string {
	var spofComponents []string
	
	// ì˜ì¡´ì„± ê·¸ë˜í”„ êµ¬ì¶•
	dependents := make(map[string][]string)
	
	for _, comp := range components {
		for _, dep := range comp.Dependencies {
			dependents[dep] = append(dependents[dep], comp.Name)
		}
	}
	
	// SPOF ì‹ë³„: ì¤‘ìš” ê²½ë¡œì— ìˆìœ¼ë©´ì„œ ëŒ€ì•ˆì´ ì—†ëŠ” ì»´í¬ë„ŒíŠ¸
	for _, comp := range components {
		if comp.CriticalPath {
			// ì´ ì»´í¬ë„ŒíŠ¸ì— ì˜ì¡´í•˜ëŠ” ë‹¤ë¥¸ ì¤‘ìš” ì»´í¬ë„ŒíŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸
			hasCriticalDependents := false
			for _, dependent := range dependents[comp.Name] {
				for _, otherComp := range components {
					if otherComp.Name == dependent && otherComp.CriticalPath {
						hasCriticalDependents = true
						break
					}
				}
			}
			
			// ì¤‘ìš” ê²½ë¡œì— ìˆìœ¼ë©´ì„œ ë‹¤ë¥¸ ì¤‘ìš” ì»´í¬ë„ŒíŠ¸ê°€ ì˜ì¡´í•˜ëŠ” ê²½ìš° SPOF
			if hasCriticalDependents || len(comp.Dependencies) == 0 {
				spofComponents = append(spofComponents, comp.Name)
			}
		}
	}
	
	return spofComponents
}

// testServiceDependencyMapping ì„œë¹„ìŠ¤ ì˜ì¡´ì„± ë§¤í•‘
func (at *ArchitectureTester) testServiceDependencyMapping(t *testing.T) {
	t.Log("ğŸ” Mapping Service Dependencies")
	
	// ì˜ì¡´ì„± ë§¤íŠ¸ë¦­ìŠ¤ ì •ì˜
	dependencies := map[string][]string{
		"gRPC Server":     {"Friend Service", "Search Service", "Event Service"},
		"Friend Service":  {"DynamoDB", "Cache Service", "Event Service"},
		"Search Service":  {"Elasticsearch", "Event Consumer"},
		"Cache Service":   {"Redis"},
		"Event Service":   {"RabbitMQ"},
		"Event Consumer":  {"RabbitMQ", "Elasticsearch"},
	}
	
	at.metrics.ModuleDependencies = dependencies
	
	// ìˆœí™˜ ì˜ì¡´ì„± ê²€ì‚¬
	circularDeps := at.detectCircularDependencies(dependencies)
	at.metrics.CircularDependencies = circularDeps
	
	// ê²°í•©ë„ ê³„ì‚°
	for service, deps := range dependencies {
		at.metrics.ComponentCoupling[service] = len(deps)
	}
	
	t.Logf("=== Service Dependency Analysis ===")
	for service, deps := range dependencies {
		t.Logf("%s depends on: %v (Coupling: %d)", service, deps, len(deps))
	}
	
	if len(circularDeps) == 0 {
		t.Logf("âœ… No circular dependencies detected")
	} else {
		t.Logf("ğŸ”´ Circular dependencies detected:")
		for _, cycle := range circularDeps {
			t.Logf("   - %s", cycle)
		}
	}
	
	// ë†’ì€ ê²°í•©ë„ ê²½ê³ 
	for service, coupling := range at.metrics.ComponentCoupling {
		if coupling > 5 {
			t.Logf("âš ï¸  High coupling detected in %s: %d dependencies", service, coupling)
		}
	}
	
	assert.Empty(t, circularDeps, "Circular dependencies detected")
}

// detectCircularDependencies ìˆœí™˜ ì˜ì¡´ì„± ê°ì§€
func (at *ArchitectureTester) detectCircularDependencies(dependencies map[string][]string) []string {
	var cycles []string
	visited := make(map[string]bool)
	recursionStack := make(map[string]bool)
	
	var dfs func(string, []string) bool
	dfs = func(node string, path []string) bool {
		visited[node] = true
		recursionStack[node] = true
		path = append(path, node)
		
		for _, neighbor := range dependencies[node] {
			if !visited[neighbor] {
				if dfs(neighbor, path) {
					return true
				}
			} else if recursionStack[neighbor] {
				// ìˆœí™˜ ë°œê²¬
				cycleStart := 0
				for i, n := range path {
					if n == neighbor {
						cycleStart = i
						break
					}
				}
				cycle := fmt.Sprintf("%v", path[cycleStart:])
				cycles = append(cycles, cycle)
				return true
			}
		}
		
		recursionStack[node] = false
		return false
	}
	
	for node := range dependencies {
		if !visited[node] {
			dfs(node, []string{})
		}
	}
	
	return cycles
}

// testCascadeFailureSimulation ì—°ì‡„ ì¥ì•  ì‹œë®¬ë ˆì´ì…˜
func (at *ArchitectureTester) testCascadeFailureSimulation(t *testing.T) {
	t.Log("ğŸ” Simulating Cascade Failure Scenarios")
	
	// ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤ë“¤
	failureScenarios := []struct {
		name              string
		failedComponent   string
		expectedImpact    []string
		maxFailureDepth   int
	}{
		{
			name:            "Redis Cache Failure",
			failedComponent: "Redis",
			expectedImpact:  []string{"Cache Service", "Friend Service", "gRPC Server"},
			maxFailureDepth: 3,
		},
		{
			name:            "DynamoDB Failure",
			failedComponent: "DynamoDB",
			expectedImpact:  []string{"Friend Service", "gRPC Server"},
			maxFailureDepth: 2,
		},
		{
			name:            "RabbitMQ Failure",
			failedComponent: "RabbitMQ",
			expectedImpact:  []string{"Event Service", "Event Consumer"},
			maxFailureDepth: 2,
		},
	}
	
	for _, scenario := range failureScenarios {
		t.Run(scenario.name, func(t *testing.T) {
			impactedServices := at.simulateComponentFailure(scenario.failedComponent)
			
			t.Logf("=== %s Impact Analysis ===", scenario.name)
			t.Logf("Failed Component: %s", scenario.failedComponent)
			t.Logf("Impacted Services: %v", impactedServices)
			t.Logf("Failure Depth: %d", len(impactedServices))
			
			// ì˜ˆìƒ ì˜í–¥ê³¼ ë¹„êµ
			if len(impactedServices) <= scenario.maxFailureDepth {
				t.Logf("âœ… Failure impact within acceptable range")
			} else {
				t.Logf("ğŸ”´ Failure impact exceeds acceptable range")
			}
			
			assert.LessOrEqual(t, len(impactedServices), scenario.maxFailureDepth+2, 
				"Cascade failure impact too broad")
		})
	}
}

// simulateComponentFailure ì»´í¬ë„ŒíŠ¸ ì¥ì•  ì‹œë®¬ë ˆì´ì…˜
func (at *ArchitectureTester) simulateComponentFailure(failedComponent string) []string {
	// ì˜ì¡´ì„± ê·¸ë˜í”„ ì—­ë°©í–¥ êµ¬ì¶•
	dependents := make(map[string][]string)
	dependencies := at.metrics.ModuleDependencies
	
	for service, deps := range dependencies {
		for _, dep := range deps {
			dependents[dep] = append(dependents[dep], service)
		}
	}
	
	// BFSë¡œ ì˜í–¥ ì „íŒŒ ê³„ì‚°
	var impacted []string
	visited := make(map[string]bool)
	queue := []string{failedComponent}
	visited[failedComponent] = true
	
	for len(queue) > 0 {
		current := queue[0]
		queue = queue[1:]
		
		for _, dependent := range dependents[current] {
			if !visited[dependent] {
				visited[dependent] = true
				impacted = append(impacted, dependent)
				queue = append(queue, dependent)
			}
		}
	}
	
	return impacted
}

// testRedundancyAnalysis ì¤‘ë³µì„± ë¶„ì„
func (at *ArchitectureTester) testRedundancyAnalysis(t *testing.T) {
	t.Log("ğŸ” Analyzing System Redundancy")
	
	// ì»´í¬ë„ŒíŠ¸ë³„ ì¤‘ë³µì„± ìˆ˜ì¤€ ì •ì˜
	redundancyLevels := map[string]struct {
		level       string  // "none", "partial", "full"
		alternatives []string
		description string
	}{
		"Redis": {
			level:       "none",
			alternatives: []string{},
			description: "Single Redis instance - SPOF",
		},
		"DynamoDB": {
			level:       "full",
			alternatives: []string{"Multi-AZ", "Auto-scaling"},
			description: "AWS managed with built-in redundancy",
		},
		"gRPC Server": {
			level:       "partial",
			alternatives: []string{"Load Balancer", "Multiple instances"},
			description: "Can be scaled horizontally",
		},
		"RabbitMQ": {
			level:       "none",
			alternatives: []string{},
			description: "Single instance - potential SPOF",
		},
		"Elasticsearch": {
			level:       "partial",
			alternatives: []string{"Cluster mode"},
			description: "Can run in cluster mode",
		},
	}
	
	t.Logf("=== Redundancy Analysis Results ===")
	
	var criticalSPOFs []string
	var partialRedundancy []string
	var fullRedundancy []string
	
	for component, redundancy := range redundancyLevels {
		switch redundancy.level {
		case "none":
			criticalSPOFs = append(criticalSPOFs, component)
			t.Logf("ğŸ”´ %s: No redundancy - %s", component, redundancy.description)
		case "partial":
			partialRedundancy = append(partialRedundancy, component)
			t.Logf("ğŸŸ¡ %s: Partial redundancy - %s", component, redundancy.description)
			t.Logf("   Alternatives: %v", redundancy.alternatives)
		case "full":
			fullRedundancy = append(fullRedundancy, component)
			t.Logf("âœ… %s: Full redundancy - %s", component, redundancy.description)
			t.Logf("   Features: %v", redundancy.alternatives)
		}
	}
	
	// ì¤‘ë³µì„± ì ìˆ˜ ê³„ì‚°
	totalComponents := len(redundancyLevels)
	redundancyScore := (float64(len(fullRedundancy))*1.0 + float64(len(partialRedundancy))*0.5) / float64(totalComponents) * 100
	
	t.Logf("=== Redundancy Summary ===")
	t.Logf("Critical SPOFs: %d (%v)", len(criticalSPOFs), criticalSPOFs)
	t.Logf("Partial Redundancy: %d (%v)", len(partialRedundancy), partialRedundancy)
	t.Logf("Full Redundancy: %d (%v)", len(fullRedundancy), fullRedundancy)
	t.Logf("Overall Redundancy Score: %.1f%%", redundancyScore)
	
	// ê°œì„  ê¶Œê³ ì‚¬í•­
	t.Logf("=== Redundancy Improvement Recommendations ===")
	for _, spof := range criticalSPOFs {
		switch spof {
		case "Redis":
			t.Logf("ğŸ”´ %s: Implement Redis Cluster or Redis Sentinel", spof)
		case "RabbitMQ":
			t.Logf("ğŸ”´ %s: Setup RabbitMQ cluster with mirrored queues", spof)
		default:
			t.Logf("ğŸ”´ %s: Implement redundancy mechanisms", spof)
		}
	}
	
	assert.Greater(t, redundancyScore, 40.0, "Redundancy score too low")
	assert.LessOrEqual(t, len(criticalSPOFs), 2, "Too many critical SPOFs")
}

// TestScalabilityAnalysis í™•ì¥ì„± ë¶„ì„ í…ŒìŠ¤íŠ¸
func TestScalabilityAnalysis(t *testing.T) {
	tester := NewArchitectureTester(t)
	defer tester.cacheService.Close()
	
	t.Run("Horizontal Scalability", func(t *testing.T) {
		tester.testHorizontalScalability(t)
	})
	
	t.Run("Vertical Scalability", func(t *testing.T) {
		tester.testVerticalScalability(t)
	})
	
	t.Run("Scalability Bottlenecks", func(t *testing.T) {
		tester.testScalabilityBottlenecks(t)
	})
	
	t.Run("Resource Utilization", func(t *testing.T) {
		tester.testResourceUtilization(t)
	})
}

// testHorizontalScalability ìˆ˜í‰ í™•ì¥ì„± í…ŒìŠ¤íŠ¸
func (at *ArchitectureTester) testHorizontalScalability(t *testing.T) {
	t.Log("ğŸ” Testing Horizontal Scalability")
	
	// ì»´í¬ë„ŒíŠ¸ë³„ ìˆ˜í‰ í™•ì¥ ê°€ëŠ¥ì„± í‰ê°€
	horizontalScalability := map[string]struct {
		scalable    bool
		limitations []string
		score       float64  // 0-100%
	}{
		"gRPC Server": {
			scalable:    true,
			limitations: []string{"Session affinity", "Load balancer required"},
			score:       90.0,
		},
		"Friend Service": {
			scalable:    true,
			limitations: []string{"Shared cache", "Event ordering"},
			score:       80.0,
		},
		"Search Service": {
			scalable:    true,
			limitations: []string{"Index consistency"},
			score:       85.0,
		},
		"Cache Service": {
			scalable:    false,
			limitations: []string{"Single Redis instance", "Data consistency"},
			score:       20.0,
		},
		"Event Service": {
			scalable:    true,
			limitations: []string{"Message ordering", "Queue partitioning"},
			score:       70.0,
		},
		"DynamoDB": {
			scalable:    true,
			limitations: []string{"Hot partitions", "Read/write capacity"},
			score:       95.0,
		},
	}
	
	t.Logf("=== Horizontal Scalability Analysis ===")
	
	var totalScore float64
	var scalableComponents []string
	var nonScalableComponents []string
	
	for component, scalability := range horizontalScalability {
		status := "âœ…"
		if !scalability.scalable {
			status = "ğŸ”´"
			nonScalableComponents = append(nonScalableComponents, component)
		} else {
			scalableComponents = append(scalableComponents, component)
		}
		
		t.Logf("%s %s: Scalability Score %.1f%%", status, component, scalability.score)
		if len(scalability.limitations) > 0 {
			t.Logf("   Limitations: %v", scalability.limitations)
		}
		
		totalScore += scalability.score
	}
	
	// ì „ì²´ ìˆ˜í‰ í™•ì¥ì„± ì ìˆ˜
	at.metrics.HorizontalScalability = totalScore / float64(len(horizontalScalability))
	
	t.Logf("=== Horizontal Scalability Summary ===")
	t.Logf("Overall Score: %.1f%%", at.metrics.HorizontalScalability)
	t.Logf("Scalable Components: %d (%v)", len(scalableComponents), scalableComponents)
	t.Logf("Non-Scalable Components: %d (%v)", len(nonScalableComponents), nonScalableComponents)
	
	// ë³‘ëª© ì»´í¬ë„ŒíŠ¸ ì‹ë³„
	for component, scalability := range horizontalScalability {
		if scalability.score < 50.0 {
			at.metrics.ScalabilityBottlenecks = append(at.metrics.ScalabilityBottlenecks, component)
		}
	}
	
	if len(at.metrics.ScalabilityBottlenecks) > 0 {
		t.Logf("ğŸ”´ Scalability Bottlenecks: %v", at.metrics.ScalabilityBottlenecks)
	}
	
	assert.Greater(t, at.metrics.HorizontalScalability, 60.0, "Horizontal scalability too low")
	assert.LessOrEqual(t, len(nonScalableComponents), 2, "Too many non-scalable components")
}

// testVerticalScalability ìˆ˜ì§ í™•ì¥ì„± í…ŒìŠ¤íŠ¸
func (at *ArchitectureTester) testVerticalScalability(t *testing.T) {
	t.Log("ğŸ” Testing Vertical Scalability")
	
	// í˜„ì¬ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¸¡ì •
	var memStats runtime.MemStats
	runtime.ReadMemStats(&memStats)
	
	currentMemory := memStats.Alloc
	maxMemory := uint64(8 * 1024 * 1024 * 1024) // 8GB ê°€ì •
	memoryUtilization := float64(currentMemory) / float64(maxMemory) * 100
	
	// CPU ì‚¬ìš©ëŸ‰ ì¶”ì • (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ì¸¡ì • í•„ìš”)
	goroutineCount := runtime.NumGoroutine()
	estimatedCPUUsage := float64(goroutineCount) / 1000.0 * 100 // ëŒ€ëµì ì¸ ì¶”ì •
	if estimatedCPUUsage > 100 {
		estimatedCPUUsage = 100
	}
	
	t.Logf("=== Current Resource Utilization ===")
	t.Logf("Memory Usage: %d MB (%.1f%% of max)", currentMemory/(1024*1024), memoryUtilization)
	t.Logf("Goroutines: %d", goroutineCount)
	t.Logf("Estimated CPU Usage: %.1f%%", estimatedCPUUsage)
	
	// ìˆ˜ì§ í™•ì¥ ê°€ëŠ¥ì„± í‰ê°€
	memoryScalability := 100 - memoryUtilization
	cpuScalability := 100 - estimatedCPUUsage
	
	at.metrics.VerticalScalability = (memoryScalability + cpuScalability) / 2
	at.metrics.ResourceUtilizationRatio = (memoryUtilization + estimatedCPUUsage) / 2
	
	t.Logf("=== Vertical Scalability Analysis ===")
	t.Logf("Memory Scalability Headroom: %.1f%%", memoryScalability)
	t.Logf("CPU Scalability Headroom: %.1f%%", cpuScalability)
	t.Logf("Overall Vertical Scalability: %.1f%%", at.metrics.VerticalScalability)
	
	// ë¦¬ì†ŒìŠ¤ ì••ë°• ìƒí™© ë¶„ì„
	if memoryUtilization > 80 {
		t.Logf("ğŸ”´ High memory utilization - consider memory optimization")
		at.metrics.ScalabilityBottlenecks = append(at.metrics.ScalabilityBottlenecks, "Memory")
	}
	if estimatedCPUUsage > 80 {
		t.Logf("ğŸ”´ High CPU utilization - consider CPU optimization")
		at.metrics.ScalabilityBottlenecks = append(at.metrics.ScalabilityBottlenecks, "CPU")
	}
	
	assert.Greater(t, at.metrics.VerticalScalability, 20.0, "Vertical scalability headroom too low")
}

// testScalabilityBottlenecks í™•ì¥ì„± ë³‘ëª© í…ŒìŠ¤íŠ¸
func (at *ArchitectureTester) testScalabilityBottlenecks(t *testing.T) {
	t.Log("ğŸ” Identifying Scalability Bottlenecks")
	
	// ì»´í¬ë„ŒíŠ¸ë³„ ì²˜ë¦¬ëŸ‰ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œë¡œëŠ” ë²¤ì¹˜ë§ˆí¬ ì¸¡ì •)
	componentThroughput := map[string]float64{
		"gRPC Server":     10000,  // RPS
		"Friend Service":  8000,   // RPS
		"Cache Service":   15000,  // RPS
		"Search Service":  5000,   // RPS
		"Event Service":   12000,  // RPS
		"DynamoDB":        20000,  // RPS
	}
	
	at.metrics.ComponentThroughput = componentThroughput
	
	// ë³‘ëª© ì§€ì  ì‹ë³„
	minThroughput := float64(1000000) // ë§¤ìš° í° ê°’ìœ¼ë¡œ ì´ˆê¸°í™”
	var bottleneckComponent string
	
	for component, throughput := range componentThroughput {
		if throughput < minThroughput {
			minThroughput = throughput
			bottleneckComponent = component
		}
	}
	
	t.Logf("=== Component Throughput Analysis ===")
	for component, throughput := range componentThroughput {
		status := "âœ…"
		if component == bottleneckComponent {
			status = "ğŸ”´"
		} else if throughput < minThroughput*1.5 {
			status = "ğŸŸ¡"
		}
		
		t.Logf("%s %s: %.0f RPS", status, component, throughput)
	}
	
	at.metrics.BottleneckIdentification["Primary"] = bottleneckComponent
	
	t.Logf("=== Bottleneck Analysis ===")
	t.Logf("Primary Bottleneck: %s (%.0f RPS)", bottleneckComponent, minThroughput)
	
	// ë³‘ëª© ìœ í˜• ë¶„ì„
	bottleneckType := "Unknown"
	switch bottleneckComponent {
	case "Search Service":
		bottleneckType = "I/O Bound - Elasticsearch queries"
	case "Friend Service":
		bottleneckType = "CPU Bound - Business logic processing"
	case "Cache Service":
		bottleneckType = "Network Bound - Redis communication"
	case "gRPC Server":
		bottleneckType = "Network Bound - Client communication"
	}
	
	at.metrics.BottleneckIdentification["Type"] = bottleneckType
	t.Logf("Bottleneck Type: %s", bottleneckType)
	
	// ê°œì„  ê¶Œê³ ì‚¬í•­
	t.Logf("=== Bottleneck Resolution Recommendations ===")
	switch bottleneckComponent {
	case "Search Service":
		t.Logf("ğŸ”§ Optimize Elasticsearch queries and add read replicas")
	case "Friend Service":
		t.Logf("ğŸ”§ Implement caching and optimize business logic")
	case "Cache Service":
		t.Logf("ğŸ”§ Implement Redis clustering and connection pooling")
	case "gRPC Server":
		t.Logf("ğŸ”§ Add load balancing and optimize serialization")
	}
}

// testResourceUtilization ë¦¬ì†ŒìŠ¤ í™œìš©ë„ í…ŒìŠ¤íŠ¸
func (at *ArchitectureTester) testResourceUtilization(t *testing.T) {
	t.Log("ğŸ” Analyzing Resource Utilization Efficiency")
	
	// ì‹œë®¬ë ˆì´ì…˜ëœ ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
	const testDuration = 30 * time.Second
	const targetRPS = 1000
	
	var wg sync.WaitGroup
	ctx, cancel := context.WithTimeout(at.ctx, testDuration)
	defer cancel()
	
	// ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘
	resourceSamples := []struct {
		timestamp time.Time
		memory    uint64
		goroutines int
	}{}
	
	monitoringDone := make(chan bool)
	go func() {
		ticker := time.NewTicker(time.Second)
		defer ticker.Stop()
		
		for {
			select {
			case <-monitoringDone:
				return
			case <-ticker.C:
				var memStats runtime.MemStats
				runtime.ReadMemStats(&memStats)
				
				sample := struct {
					timestamp time.Time
					memory    uint64
					goroutines int
				}{
					timestamp:  time.Now(),
					memory:     memStats.Alloc,
					goroutines: runtime.NumGoroutine(),
				}
				resourceSamples = append(resourceSamples, sample)
			}
		}
	}()
	
	// ë¶€í•˜ ìƒì„±
	requestCount := 0
	for i := 0; i < 10; i++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()
			
			ticker := time.NewTicker(time.Second / time.Duration(targetRPS/10))
			defer ticker.Stop()
			
			for {
				select {
				case <-ctx.Done():
					return
				case <-ticker.C:
					// ê°€ë²¼ìš´ ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
					key := fmt.Sprintf("resource_test_%d_%d", workerID, requestCount)
					value := fmt.Sprintf("value_%d", time.Now().UnixNano())
					
					at.cacheService.Set(at.ctx, key, value, time.Minute)
					requestCount++
				}
			}
		}(i)
	}
	
	wg.Wait()
	close(monitoringDone)
	
	// ë¦¬ì†ŒìŠ¤ íš¨ìœ¨ì„± ë¶„ì„
	if len(resourceSamples) > 0 {
		var totalMemory uint64
		var maxMemory uint64
		var minMemory uint64 = resourceSamples[0].memory
		
		var totalGoroutines int
		var maxGoroutines int
		
		for _, sample := range resourceSamples {
			totalMemory += sample.memory
			if sample.memory > maxMemory {
				maxMemory = sample.memory
			}
			if sample.memory < minMemory {
				minMemory = sample.memory
			}
			
			totalGoroutines += sample.goroutines
			if sample.goroutines > maxGoroutines {
				maxGoroutines = sample.goroutines
			}
		}
		
		avgMemory := totalMemory / uint64(len(resourceSamples))
		avgGoroutines := totalGoroutines / len(resourceSamples)
		
		memoryVariability := float64(maxMemory-minMemory) / float64(avgMemory) * 100
		
		t.Logf("=== Resource Utilization Analysis ===")
		t.Logf("Test Duration: %v", testDuration)
		t.Logf("Target RPS: %d", targetRPS)
		t.Logf("Requests Processed: %d", requestCount)
		
		t.Logf("=== Memory Analysis ===")
		t.Logf("Average Memory: %d MB", avgMemory/(1024*1024))
		t.Logf("Peak Memory: %d MB", maxMemory/(1024*1024))
		t.Logf("Memory Variability: %.1f%%", memoryVariability)
		
		t.Logf("=== Goroutine Analysis ===")
		t.Logf("Average Goroutines: %d", avgGoroutines)
		t.Logf("Peak Goroutines: %d", maxGoroutines)
		
		// íš¨ìœ¨ì„± ì ìˆ˜ ê³„ì‚°
		actualRPS := float64(requestCount) / testDuration.Seconds()
		rpsEfficiency := (actualRPS / float64(targetRPS)) * 100
		
		memoryPerRequest := float64(avgMemory) / actualRPS
		goroutinesPerRPS := float64(avgGoroutines) / actualRPS
		
		// ì¢…í•© íš¨ìœ¨ì„± ì ìˆ˜
		resourceEfficiency := 100.0 / (memoryPerRequest/1024 + goroutinesPerRPS*10)
		at.metrics.ResourceUtilizationRatio = resourceEfficiency
		
		t.Logf("=== Efficiency Metrics ===")
		t.Logf("Actual RPS: %.1f (%.1f%% of target)", actualRPS, rpsEfficiency)
		t.Logf("Memory per Request: %.1f KB", memoryPerRequest/1024)
		t.Logf("Goroutines per RPS: %.3f", goroutinesPerRPS)
		t.Logf("Resource Efficiency Score: %.2f", resourceEfficiency)
		
		// íš¨ìœ¨ì„± í‰ê°€
		if resourceEfficiency > 10.0 {
			t.Logf("âœ… Good resource efficiency")
		} else if resourceEfficiency > 5.0 {
			t.Logf("ğŸŸ¡ Moderate resource efficiency")
		} else {
			t.Logf("ğŸ”´ Poor resource efficiency")
		}
		
		assert.Greater(t, rpsEfficiency, 80.0, "RPS efficiency too low")
		assert.Greater(t, resourceEfficiency, 3.0, "Resource efficiency too low")
	}
}

// TestArchitectureSummary ì•„í‚¤í…ì²˜ ë¶„ì„ ì¢…í•© ë³´ê³ ì„œ
func TestArchitectureSummary(t *testing.T) {
	tester := NewArchitectureTester(t)
	defer tester.cacheService.Close()
	
	t.Log("ğŸ“Š Architecture Analysis Summary Report")
	
	// ì „ì²´ ì•„í‚¤í…ì²˜ ì ìˆ˜ ê³„ì‚°
	architectureScore := tester.calculateOverallArchitectureScore()
	
	t.Logf("=== Architecture Health Summary ===")
	t.Logf("Overall Architecture Score: %.1f/100", architectureScore)
	
	t.Logf("=== Single Points of Failure ===")
	if len(tester.metrics.SinglePointsOfFailure) == 0 {
		t.Logf("âœ… No critical SPOFs identified")
	} else {
		t.Logf("ğŸ”´ Critical SPOFs: %v", tester.metrics.SinglePointsOfFailure)
	}
	
	t.Logf("=== Scalability Assessment ===")
	t.Logf("Horizontal Scalability: %.1f%%", tester.metrics.HorizontalScalability)
	t.Logf("Vertical Scalability: %.1f%%", tester.metrics.VerticalScalability)
	if len(tester.metrics.ScalabilityBottlenecks) > 0 {
		t.Logf("Bottlenecks: %v", tester.metrics.ScalabilityBottlenecks)
	}
	
	t.Logf("=== Coupling Analysis ===")
	if len(tester.metrics.CircularDependencies) == 0 {
		t.Logf("âœ… No circular dependencies")
	} else {
		t.Logf("ğŸ”´ Circular dependencies: %v", tester.metrics.CircularDependencies)
	}
	
	// ì‹¬ê°ë„ë³„ ì´ìŠˆ ë¶„ë¥˜
	criticalIssues := len(tester.metrics.SinglePointsOfFailure)
	if len(tester.metrics.CircularDependencies) > 0 {
		criticalIssues++
	}
	
	majorIssues := len(tester.metrics.ScalabilityBottlenecks)
	if tester.metrics.HorizontalScalability < 50 {
		majorIssues++
	}
	if tester.metrics.VerticalScalability < 30 {
		majorIssues++
	}
	
	t.Logf("=== Issue Severity Breakdown ===")
	t.Logf("Critical Issues: %d", criticalIssues)
	t.Logf("Major Issues: %d", majorIssues)
	
	// ê°œì„  ìš°ì„ ìˆœìœ„
	t.Logf("=== Architecture Improvement Priorities ===")
	if criticalIssues > 0 {
		t.Logf("ğŸ”´ PRIORITY 1: Address Single Points of Failure")
		for _, spof := range tester.metrics.SinglePointsOfFailure {
			t.Logf("   - Implement redundancy for %s", spof)
		}
	}
	
	if len(tester.metrics.ScalabilityBottlenecks) > 0 {
		t.Logf("ğŸŸ¡ PRIORITY 2: Resolve Scalability Bottlenecks")
		for _, bottleneck := range tester.metrics.ScalabilityBottlenecks {
			t.Logf("   - Optimize %s component", bottleneck)
		}
	}
	
	if len(tester.metrics.CircularDependencies) > 0 {
		t.Logf("ğŸŸ¡ PRIORITY 3: Eliminate Circular Dependencies")
		for _, cycle := range tester.metrics.CircularDependencies {
			t.Logf("   - Refactor dependency cycle: %s", cycle)
		}
	}
	
	// ì „ì²´ í‰ê°€
	if architectureScore >= 80 {
		t.Logf("âœ… Excellent architecture quality")
	} else if architectureScore >= 60 {
		t.Logf("ğŸŸ¡ Good architecture with room for improvement")
	} else {
		t.Logf("ğŸ”´ Architecture needs significant improvement")
	}
	
	// ì•„í‚¤í…ì²˜ ì„±ìˆ™ë„ í‰ê°€
	maturityLevel := tester.assessArchitecturalMaturity()
	t.Logf("Architecture Maturity Level: %s", maturityLevel)
}

// calculateOverallArchitectureScore ì „ì²´ ì•„í‚¤í…ì²˜ ì ìˆ˜ ê³„ì‚°
func (at *ArchitectureTester) calculateOverallArchitectureScore() float64 {
	score := 100.0
	
	// SPOF íŒ¨ë„í‹°
	score -= float64(len(at.metrics.SinglePointsOfFailure)) * 15
	
	// ìˆœí™˜ ì˜ì¡´ì„± íŒ¨ë„í‹°
	score -= float64(len(at.metrics.CircularDependencies)) * 10
	
	// í™•ì¥ì„± ì ìˆ˜ ë°˜ì˜
	scalabilityScore := (at.metrics.HorizontalScalability + at.metrics.VerticalScalability) / 2
	score = score*0.7 + scalabilityScore*0.3
	
	// ë³‘ëª© íŒ¨ë„í‹°
	score -= float64(len(at.metrics.ScalabilityBottlenecks)) * 5
	
	if score < 0 {
		score = 0
	}
	
	return score
}

// assessArchitecturalMaturity ì•„í‚¤í…ì²˜ ì„±ìˆ™ë„ í‰ê°€
func (at *ArchitectureTester) assessArchitecturalMaturity() string {
	score := at.calculateOverallArchitectureScore()
	
	if score >= 90 {
		return "Advanced - Production-ready with high resilience"
	} else if score >= 75 {
		return "Intermediate - Good foundation with minor improvements needed"
	} else if score >= 60 {
		return "Basic - Functional but requires significant hardening"
	} else {
		return "Initial - Major architectural improvements required"
	}
}